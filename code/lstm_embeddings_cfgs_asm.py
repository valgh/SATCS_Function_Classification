# -*- coding: utf-8 -*-
"""LSTM_embeddings_CFGs_asm.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1-CixrzRBvIseifbtEFjD0FXqwE5JZ2xE
"""

# mounting drive...
from google.colab import drive
drive.mount("/content/gdrive/")

# retrieving the classes
import json
classes = json.load(open("/content/gdrive/My Drive/func_classified_asm_tfidf_10_120000.json", "r"))
print(type(classes))
for centroid in classes:
  print(len(classes[centroid]))
print(classes[str(3)])
print(len(classes[str(3)]))

import json
func2walk = json.load(open("/content/gdrive/My Drive/func2walkG.json", "r"))
v = json.load(open("/content/gdrive/My Drive/vocab_nodes.json", "r"))
func2walk_2 = json.load(open("/content/gdrive/My Drive/func2walkG_2.json", "r"))
func2walk_3 = json.load(open("/content/gdrive/My Drive/func2walkG_3.json", "r"))
func2walk_4 = json.load(open("/content/gdrive/My Drive/func2walkG_4.json", "r"))
v_2 = json.load(open("/content/gdrive/My Drive/vocab_nodes_2.json", "r"))
v_3 = json.load(open("/content/gdrive/My Drive/vocab_nodes_3.json", "r"))
v_4 = json.load(open("/content/gdrive/My Drive/vocab_nodes_4.json", "r"))
func2walk.update(func2walk_2)
func2walk.update(func2walk_3)
func2walk.update(func2walk_4)
v.update(v_2)
v.update(v_3)
v.update(v_4)
print(len(func2walk))
print(len(v))

import gc
gc.collect()
class2adj = {}
for centroid in classes:
  class2adj[centroid] = []
  for func in classes[centroid]:
    if func in func2walk:
      class2adj[centroid].append(func2walk[func])

to_rem = ['1', '2', '3', '4', '5', '6']
#to_rem = []
#for centroid in class2adj:
#  if len(class2adj[centroid])>19000 or len(class2adj[centroid])<12000:
#    to_rem.append(centroid)

for i in to_rem:
  class2adj.pop(i)

# balancing the dataset...

for centroid in class2adj:
  class2adj[centroid] = class2adj[centroid][:12280]


for centroid in class2adj:
  print(centroid, len(class2adj[centroid]))

#print(class2adj[str(1)])
#print(class2adj[str(1)][1])

# now we need to split this dataset we obtained,
# and then to make a dataloader for it in order to
# be processed by a CNN.

adj_mats = []
labels = []
for centroid in class2adj:
  for adj_mat in class2adj[centroid]:
    adj_mats.append(adj_mat)
    labels.append(int(centroid))


# now we split our dataset into train, development and test
from sklearn.model_selection import train_test_split
rest_adj, test_adj, rest_labels, test_labels = train_test_split(adj_mats, labels, test_size=0.1, random_state=1)
train_adj, dev_adj, train_labels, dev_labels = train_test_split(rest_adj, rest_labels, test_size=0.1, random_state=1)

print("Train size:", len(train_adj))
print("Dev size:", len(dev_adj)) #not actually used here
print("Test size:", len(test_adj))

# and now we get the number of labels with corresponding indexes
target_names = list(set(labels))
label2idx = {label: idx for idx, label in enumerate(target_names)}
print(label2idx)
print(type(train_adj))
print(type(train_labels))

import numpy as np
to_train_sp = train_adj + dev_adj
to_label = train_labels + dev_labels

# now the adjacency matrices all have different dimension, so
# we need all of them to have the same dimension.
# First, we turn them all into arrays:

to_train = []
for adj_mat_sp in to_train_sp:
  to_train.append(np.array(adj_mat_sp, dtype = np.float32))

print(type(to_train[0]))
print(to_train[0])
print(to_label[0])
print(np.shape(to_train[0]))
print(type(np.shape(to_train[0])))

def max_dim(to_train):
  max = None
  for adj_mat in to_train:
    size = adj_mat.shape
    if max == None:
      max = size
    elif size > max:
      print(size)
      max = size
  return max

print("\n=======MAX LEN MATRIX:==========\n")
d = max_dim(to_train)
print(d)

X_training = to_train
# encoding the labels
def encode_labels(dataset):
  labels = []
  for l in dataset:
    labels.append(label2idx[l])
  return np.asarray(labels)

y_training = encode_labels(to_label)
print(y_training[0])

vocab = np.array([list(vo) for vo in v.values()])
print(np.shape(vocab))

#now we can create the dataset and the dataloader for Pytorch
import torch
from torch.utils.data import TensorDataset, DataLoader

#Tensor Dataset
train_data = TensorDataset(torch.LongTensor(X_training), torch.from_numpy(y_training))
print(train_data[0])
#DataLoader
train_loader = DataLoader(train_data, shuffle=True, batch_size=50)
print(train_loader)

# now we build up our neural network
# keep in mind the input!

import torch
from torch import nn

class RNN(nn.Module) :
    def __init__(self, vocab_size=len(v), embedding_dim=100, hidden_dim=100) :
        super().__init__()
        self.hidden_dim = hidden_dim
        self.embeddings = nn.Embedding(vocab_size, embedding_dim)
        self.embeddings.weight = nn.Parameter(torch.from_numpy(vocab).float())
        # once again we freeze the embeddings, they will only be a lookup table
        self.embeddings.requires_grad = False
        self.rnn = nn.LSTM(embedding_dim, hidden_dim, num_layers=1, bidirectional=True, batch_first=True)
        self.output = len(class2adj)
        self.linear = nn.Linear(2*hidden_dim, self.output)
        
    def forward(self, x, x_len):
        x = self.embeddings(x)
        out, hidden = self.rnn(x)
        out_f = out[range(len(out)), x_len - 1, :self.hidden_dim]
        out_r = out[:, 0, self.hidden_dim:]
        out_m = torch.cat((out_f, out_r), 1)
        x = self.linear(out_m)
        x = torch.squeeze(x, 1)
        return torch.sigmoid(x)

model = RNN()
print(model)
loss_function = nn.CrossEntropyLoss()
opt = torch.optim.Adam(model.parameters(), lr=0.001)

use_cuda = torch.cuda.is_available()
device = torch.device("cuda" if use_cuda else "cpu") 
model.to(device)

#DEFINING THE TRAINING STEP
def train_step(x, x_len, y):
  model.train()
  y_pred = model(x, x_len)
  loss_epoch = loss_function(y_pred, y)
  loss_epoch.backward()
  opt.step()
  opt.zero_grad()

#TRAINING STEP
import torch
from tqdm import tqdm_notebook as tqdm
for epoch in tqdm(range(20)):
  model.train()
  for Xb, yb in train_loader:
    Xb = Xb.to(device) #move into device 
    Xb_len = len(Xb)
    yb = yb.to(device) #move into device 
    train_step(Xb, Xb_len, yb)

# now we prepare the test/evaluation dataloader
y_testing = encode_labels(test_labels)
to_test = []
for adj_mat in test_adj:
  to_test.append(adj_mat)
X_test = to_test
print(y_testing[1])
print(X_test[1])

#Tensor Dataset
test_data = TensorDataset(torch.LongTensor(X_test), torch.from_numpy(y_testing))
print(test_data)
print(test_data[1])
#DataLoader
test_loader = DataLoader(test_data, shuffle=True, batch_size=50)
print(test_loader)

# EVALUATION OF THE NETWORK
# now evaluating the performances on the test_dataset
with torch.no_grad():
  Y_pred = []
  Y_true = []
  model.eval()
  for Xb, yb in test_loader:
    Xb = Xb.to(device)
    Xb_len = len(Xb)
    y_pred = model(Xb, Xb_len)
    yb = yb.to(device)
    correct = (y_pred.max(dim=1)[1] == yb)
    Y_pred.append(y_pred.max(dim=1)[1].cpu())
    Y_true.append(yb.cpu())
  print(torch.mean(correct.float()).item())

from sklearn.metrics import confusion_matrix, precision_recall_fscore_support, classification_report
print(confusion_matrix(torch.cat(Y_true), torch.cat(Y_pred)))

print("\nTest performance:", precision_recall_fscore_support(torch.cat(Y_true), torch.cat(Y_pred), average="micro"))

print(classification_report(torch.cat(Y_true), torch.cat(Y_pred), zero_division=0))
