# -*- coding: utf-8 -*-
"""preprocessing_adjmat_asm.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/13pGKTouMjLf5udQ0baAngdQ0J1OAwXR9
"""

# mounting drive...
from google.colab import drive
drive.mount("/content/gdrive/")

# now we can access the drive
# and we retrieve the data
import os
data_path = "/content/gdrive/My Drive/data/"
list_dir = os.listdir(data_path)
print(list_dir)

# we now make a dictionary out of the data directory: FUNC_NAME -> FUNC_JSON_DATA
import json
func_dict = {}
i=0
for func in list_dir:
  func_name = func[:-5]
  i+=1
  if i == 1000:
    print("reporting...\n")
    i=0
  with open(data_path+func) as f:
    func_json_data = json.load(f)
    func_dict[func_name] = func_json_data

for func in func_dict:
  print(func, func_dict[func])
  break

# now we save this to a JSON file.
json.dump(func_dict, open("/content/gdrive/My Drive/func_dict_raw.json", "w"))

# reload all the json files obtained sequentially, execution after execution
import json
func_dict = json.load(open("/content/gdrive/My Drive/func_dict_raw_4.json", "r"))
print(len(func_dict))

# now we need to turn each function in its own adjacency matrix
# we import the file we wish to process 
# with the topological sort list, this gets a CFG and it returns a related adjacency matrix with the special property
# that if node x is in list in position j, than any node in a position i>j is either after x in a topological sort
# or is uncomparable in the topological sort

def get_back_edges(G,source):
    if source is None:
        # produce edges for all components
        nodes = G
    else:
        # produce edges for components with source
        nodes = [source]
    visited=set()
    back_edges=set()
    for start in nodes:
        if start in visited:
            continue
        visited.add(start)
        stack = [(start,iter(G[start]))]
        while stack:
            parent,children = stack[-1]
            try:
                child = next(children)
                if child not in visited:
                    visited.add(child)
                    stack.append((child,iter(G[child])))
                else:
                    #detecting if a backedge
                    loop=[]
                    for x in reversed(stack):
                        loop.append(x[0])
                        if x[0] == child:
                            yield (loop,(parent,child))
                            break
            except StopIteration:
                stack.pop()


#takes an input a CFG and it removes all back edges
def cfg_to_dacfg_trivial(G, entrypoint):
    back_edges=[ x for x in get_back_edges(G,entrypoint)]
    edges=[x[1] for x in back_edges]
    for x in edges:
        G.remove_edge(x[0], x[1])
    return G

def get_entrypoint(cfg):
    entrypoint=None
    for x in cfg.nodes(data=True):
        if x[1]['entrypoint']==True:
            entrypoint=x[0]
            break
    return entrypoint

import json
import networkx as nx
from networkx.readwrite import json_graph

for func in func_dict:
  print(func)
  G = json_graph.node_link_graph(func_dict[func])
  attr = nx.get_node_attributes(G, 'entrypoint')
  i = 0
  for node in attr:
    if attr[node] == True:
      for index, n in enumerate(G.nodes()):
        if n == node:
          print(index)
  e = get_entrypoint(G)
  G = cfg_to_dacfg_trivial(G, e)
  poset = list(nx.topological_sort(G))
  adj_mat = nx.adjacency_matrix(G, poset)
  adj_mat_non_topological = nx.adjacency_matrix(G)
  print(adj_mat.todense())
  print(adj_mat_non_topological.todense())
  i+=1
  if i == 4:
    break

# so this is what we need to do now:
# for each FUNC_NAME in CLASSES, retrieve its ADJACENCY MATRIX
# and then build a dictionary so that we have CLASS -> LIST OF FUNCTIONS AS ADJ MATRICES
# we do this first for the adjacency matrices ordered in topological fashion,
# then in the next block we do the same but without topological order for what's to come next
func2adj = {}
func2entrypoint = {}
for func in func_dict:
  G = json_graph.node_link_graph(func_dict[func])
  attr = nx.get_node_attributes(G, 'entrypoint')
  for node in attr:
    if attr[node] == True:
      for index, n in enumerate(G.nodes()):
        if n == node:
          func2entrypoint[func] = index
          break
      break
  e = get_entrypoint(G)
  G = cfg_to_dacfg_trivial(G, e)
  poset = list(nx.topological_sort(G))
  adj_mat = nx.adjacency_matrix(G, poset).todense()
  func2adj[func] = adj_mat.tolist()
#print(func2adj['abort'])
#print(func2entrypoint['abort'])

# now we save them to a JSON file.
json.dump(func2adj, open("/content/gdrive/My Drive/func2adj_4_t.json", "w"))
json.dump(func2entrypoint, open("/content/gdrive/My Drive/func2ent_4_t.json", "w"))

# without topological order, for the embeddings with 
# random walk
func2adj = {}
func2entrypoint = {}
for func in func_dict:
  G = json_graph.node_link_graph(func_dict[func])
  attr = nx.get_node_attributes(G, 'entrypoint')
  for node in attr:
    if attr[node] == True:
      for index, n in enumerate(G.nodes()):
        if n == node:
          func2entrypoint[func] = index
          break
      break
  adj_mat = nx.adjacency_matrix(G).todense()
  func2adj[func] = adj_mat.tolist()
#print(func2adj['abort'])
#print(func2entrypoint['abort'])

# now we save them to a JSON file.
json.dump(func2adj, open("/content/gdrive/My Drive/func2adj_2.json", "w"))
json.dump(func2entrypoint, open("/content/gdrive/My Drive/func2ent_2.json", "w"))